{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So this code goes through deciding what elements in each of the two databases are \"the same\"\n",
    "\n",
    "# Required modules\n",
    "\n",
    "# Python inbuilt\n",
    "import json\n",
    "import csv\n",
    "import subprocess\n",
    "\n",
    "# Extra downloaded\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first part of the analysis is to see what happens when ABRicate is run with both the Resfinder and CARD database\n",
    "# To identify the extent of difference in how each method identifies \"TRANSMISSIBLE RESISTANCE GENES\"\n",
    "# Note by the fact we are only looking at \"TRANSMISSIBLE RESISTNACE GENES\" CARD and Resfinder dbs should have all necessary genes in them\n",
    "\n",
    "# For the database comparison, we use the two following simple definitions\n",
    "\n",
    "# 0 = Identical sequence\n",
    "# 1 = Identical protein\n",
    "\n",
    "# For two programs to identify the same thing they have to identify everything identically at the protein level\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we PARSE the databases \n",
    "# CARD\n",
    "card_db = \"card_20191023/card-data/card.json\"\n",
    "with open(card_db) as f:\n",
    "    card_db = json.load(f)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting and comparing the two databases\n",
    "\n",
    "\n",
    "So for comparing CARD with Resfinder results, were aiming to identify transmissible proteins from each\n",
    "In card this approximately equates to the **protein homolog model**.\n",
    "\n",
    "This process has several steps\n",
    "1. For each database, create a csv which contains an easily accesible set of information for comparison\n",
    "- Note for working out whether there is a translation link, we translate with translation table 11, then disregard the first element and remove any trailing stop codon sequence.\n",
    "- Looking at the remaining sequence, if they match then there is a link, if not no link\n",
    "- If no link leave blank, and each DNA with no link will be put next to its directly translated protein\n",
    "2. As part of making a database each element will get a new identifier which will be used to make sure all programs can process them the same way\n",
    "- e.g. cardnewid_x \n",
    "2. Match these CSVs according to protein sequence\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### The card CSV will have the following headers\n",
    "\n",
    "1. prot_seq\n",
    "2. dna_seq\n",
    "3. card_name\n",
    "4. card_newname\n",
    "5. aro_id\n",
    "6. translation_link\n",
    "\n",
    "#### The resfinder CSV will have the following headers\n",
    "\n",
    "1. prot_seq\n",
    "2. dna_seq\n",
    "3. resfinder_name\n",
    "4. resfinder_newname\n",
    "\n",
    "\n",
    "#### DATABASE QUALITY CONTROL\n",
    "\n",
    "For each database, we need to create a unique identifier for elements\n",
    "This based on its DNA sequence only\n",
    "This in effect will remove a sequence which has the same DNA sequence but different name in any given database\n",
    "\n",
    "e.g. supposed the following sequence AACTTGCTA was called both gene1 and gene2 in the formated databases it will only be called newgene1\n",
    "\n",
    "Duplicates names for different sequences will be asigned new names. The aim of this approach is to retain the databases in as close to original format as possible , while making up to date databases readable for each of the 4 programs\n",
    "\n",
    "**Note the resfinder database is produced by concatinating each of the specific antibiotic databases, this results in some duplicates which we remove, (i.e. the genes which affect more than one type of antibiotic, (for example quinolone resistance causing aac variant)**\n",
    "\n",
    "###### Removed variants below\n",
    "\n",
    "So the duplicate names we will have censored using this method\n",
    "1. \"blaOXA-347_1_JN086160\" , same sequence as \"blaOXA-347_1_ACWG01000053\" (2 refs)\n",
    "2. \"blaZ_129_CP003194\", same sequence as \"blaZ_125_CP003194\" (curation)\n",
    "3. \"blaIMP-58_1_KU647281\",  same sequence as \"blaIMP-58_1_KU647281\" (duplciate)\n",
    "4. \"blaCTX-M-63_1_AB205197\", same sequence as \"blaCTX-M-63_1_EU660216\" (2 refs)\n",
    "5. \"blaCMY-110_1_AB872957\", same sequence as \"blaCMY-110_1_AB872957\" (duplicate)\n",
    "6. \"blaCMY-104_1_KF150216\", same sequence as \"blaCMY-104_1_KF150216\" (duplicate)\n",
    "7. \"blaACC-4_2_EF504260\", same sequence as \"blaACC-4_1_GU256641\" (2 refs)\n",
    "8. \"blaSHV-36_1_AF467947\", same sequence as \"blaSHV-36_1_AF467947\" (duplicate)\n",
    "9. \"blaOXA-60_1_AF525303\", same sequence as \"blaOXA-60_1_AF525303\" (duplicate)\n",
    "10. \"blaFRI-1_1_KT192551\", same sequence as \"blaFRI-1_1_KT192551\" (duplicate)\n",
    "11. \"cfr_1_AM408573\", same sequence as \"cfr_1_AM408573\" (duplicate)\n",
    "12. \"cfr_2_AJ879565\", same sequence as \"cfr_2_AJ879565\" (duplicate)\n",
    "13. \"cfr(B)_3_KR610408\", same sequence as \"cfr(B)_3_KR610408\" (duplicate)\n",
    "14. aac(6')-Ib-cr_1_DQ303918, same sequence as \"aac(6')-Ib-cr_1_DQ303918\" (duplicate)\n",
    "15. aac(6')-Ib-cr_2_EF636461 , same sequence as \"aac(6')-Ib-cr_2_EF636461\" (duplicate)\n",
    "16. dfrA22_3_FM957884, same sequence as dfrA33_1_FM957884 (curation)\n",
    "\n",
    "#### DATABASE PREPARATION CHOICES\n",
    "\n",
    "\n",
    "**ARIBA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2617"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CARD\n",
    "\n",
    "# Note for this we are using the CARD 23rd Oct 2019 release.\n",
    "\n",
    "# Note to add , it appears that the DNA sequences do always translate to the protein, although the DNA sequence is not always in the correct frame\n",
    "# To keep it simple, I will just use the DNA database\n",
    "# And then compare with the resfinder database using the protein\n",
    "\n",
    "# Note 7 have 2 DNA sequences. These are identical in all but Erm(44)v's case \n",
    "# Given the ARO sequence identifier is in effect our unique identifier, I will drop this one, and just use the first\n",
    "# This is unlikely to be relavent in gram negatives as only been seen in S. saprophyticus and confers resistance to macrolides (which GNRs are generally innately resistant to)\n",
    "# We will use the scond encountered\n",
    "\n",
    "card_formatted_no = 1\n",
    "\n",
    "card_dict = {}\n",
    "\n",
    "card_recs = []\n",
    "\n",
    "with open(\"card_20191023_link.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    for key in card_db.keys():\n",
    "        try:\n",
    "            # First we extract relavent data\n",
    "            if card_db[key]['model_type'] == \"protein homolog model\":\n",
    "                aro_id = card_db[key]['ARO_id']\n",
    "                name = card_db[key][\"ARO_name\"]\n",
    "                for k in card_db[key]['model_sequences']['sequence'].values():\n",
    "                    card_prot = k['protein_sequence']['sequence']\n",
    "                    card_dna = k['dna_sequence']['sequence']\n",
    "                # This way we automatically keep the second sequence\n",
    "                # Then we rename things so that each program formatts them properly.\n",
    "                new_id = \"cardnewid_{0}\" .format(card_formatted_no)\n",
    "                card_formatted_no += 1\n",
    "                card_seq = Seq(card_dna)\n",
    "                card_rec = SeqRecord(card_seq, id=new_id, description=\"\")\n",
    "                card_recs.append(card_rec)\n",
    "                # Now we want to create some stuff for a linking database to compare the two\n",
    "                orig_id = name + \"_ARO\"+ aro_id\n",
    "                card_dict[new_id] = {\"orig_id\":orig_id, \n",
    "                                    \"dna_seq\":card_dna,\n",
    "                                    \"prot_seq\":card_prot}\n",
    "                writer.writerow([orig_id, new_id, str(card_seq)])\n",
    "        except:\n",
    "            # This line removes the 1 entry which just has a description of the database\n",
    "            pass\n",
    "\n",
    "SeqIO.write(card_recs, \"card_20191023_formatted.fasta\", \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resfinder\n",
    "\n",
    "# So this code does the following\n",
    "# Firstly, you concatenate and read in the database\n",
    "subprocess.check_call(\"cat resfinder_20191001/*.fsa > resfinder.fasta\", shell=True)\n",
    "resfinder_initdb = SeqIO.parse(\"resfinder_20191001/resfinder.fasta\", \"fasta\")\n",
    "\n",
    "# Then you assign a new unique name to each element of the database\n",
    "# Note some elements are removed (see above) to ensure each DNA sequence only has one name\n",
    "# The way things are linked are put into a resfinder_20191001_link.csv file\n",
    "# The final database is then written into a resfinder_20191001_formatted.fasta\n",
    "resfinder_db = {}\n",
    "identified_seqs = []\n",
    "newid = 0\n",
    "for k in resfinder_initdb:\n",
    "    if str(k.seq) not in identified_seqs:\n",
    "        newid += 1\n",
    "        identified_seqs.append(str(k.seq))\n",
    "        resfinder_db[\"resfindernewid_{0}\" .format(newid)] = k\n",
    "out_recs = []\n",
    "with open(\"resfinder_20191001_link.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f, delimiter = \",\")\n",
    "    for k in resfinder_db:\n",
    "        writer.writerow([k, resfinder_db[k].id, str(resfinder_db[k].seq)])\n",
    "        k_id = k\n",
    "        k_desc = \"\"\n",
    "        k_seq = resfinder_db[k].seq\n",
    "        k_rec = SeqRecord(k_seq, id=k_id, description=k_desc)\n",
    "        out_recs.append(k_rec)\n",
    "\n",
    "SeqIO.write(out_recs, \"resfinder_20191001_formatted.fasta\", \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next comes how to format the databases \n",
    "\n",
    "As an additional side point this database then needs to be formatted to meet ABRicate's structure\n",
    "The script below does this\n",
    "\n",
    "~~~\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "base_db = SeqIO.parse(\"resfinder_20191001_formatted.fasta\",\"fasta\")\n",
    "abricate_recs = []\n",
    "\n",
    "for k in base_db:\n",
    "    k_seq = k.seq\n",
    "    k_id = \"resfinderformatted~~~{0}~~~00{1}\".format(k.id, \"{:04d}\" .format(int(k.id.split(\"_\")[-1])))\n",
    "    k_rec = SeqRecord(k_seq, id=k_id, description=\"\")\n",
    "    abricate_recs.append(k_rec)\n",
    "SeqIO.write(abricate_recs, \"sequences\", \"fasta\")\n",
    "~~~\n",
    "\n",
    "\n",
    "##### Each of the following illustrates the steps required to prep the database\n",
    "\n",
    "**preparing the ABRicate_db**\n",
    "\n",
    "~~~\n",
    "python abricate_format.py \n",
    "mkdir abricate_db\n",
    "mv sequences abricate_db/\n",
    "cd abricate_db\n",
    "makeblastdb -in sequences -title rf102019 -dbtype nucl -hash_index\n",
    "cd ..\n",
    "~~~\n",
    "**preparing the ARIBA db**\n",
    "~~~\n",
    "mkdir ariba_db\n",
    "cp  resfinder_20191001_formatted.fasta ariba_db\n",
    "cd ariba_db\n",
    "ariba prepareref --all_coding no -f resfinder_20191001_formatted.fasta formatted_dbs/ariba_db\n",
    "cd ..\n",
    "~~~\n",
    "\n",
    "**Preparing the KmerResistance db**\n",
    "** Note for KmerResistance, there is an additional file**\n",
    "### add to this text ### should primarily been in the supplements\n",
    "\n",
    "The exception to this was that KmerResistance requires a “bacteria.fsa” FASTA file of all complete genomes in NCBI’s RefSeq database to filter low-coverage matches. As of writing, the version used by KmerResistance’s authors was not publicly available, however we attempted mitigate this using two alterations; replacing the file using a FASTA containing all complete genomes as identified by Centrifuge-download[14], and applying an average depth of coverage cut-off of >5x to KmerResistance results. For ABRicate (which uses BLASTn to search assemblies), assemblies were produced using SPAdes[8] run with default parameters. \n",
    "\n",
    "~~~\n",
    "mkdir kmerres_db\n",
    "mv bacteria.fsa kmerres_db\n",
    "cp resfinder_20191001_formatted.fasta kmerres_db/\n",
    "cd kmerres_db\n",
    "kma index -i bacteria.fsa -o bacteria -Sparse ATG\n",
    "mv resfinder_20191001_formatted.fasta kmerres_fasta.fa\n",
    "kma_index -i kmerres_fasta.fa -o kmerres_fasta\n",
    "cd ..\n",
    "~~~\n",
    "\n",
    "**Preparing the SRST2 db**\n",
    "~~~\n",
    "mkdir srst2_db\n",
    "cd srst2_db/\n",
    "mv resfinder_20191001_formatted.fasta rawseqs.fasta\n",
    "cd-hit-est -i rawseqs.fasta -o rawseqs_cdhit90 -d 0 > rawseqs_cdhit90.stdout\n",
    "python /srst2/database_clustering/cdhit_to_csv.py --cluster_file rawseqs_cdhit90.clstr --infasta rawseqs.fasta --outfile rawseqs_clustered.csv\n",
    "python /srst2/database_clustering/csv_to_gene_db.py -t rawseqs_clustered.csv -o seqs_clustered.fasta -f rawseqs.fasta -c 4\n",
    "cd ..\n",
    "~~~\n",
    "\n",
    "** A similar method is used for preparing the card and legacy resfinder databases **\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timdavies/anaconda/lib/python3.6/site-packages/Bio/Seq.py:2715: BiopythonWarning: Partial codon, len(sequence) not a multiple of three. Explicitly trim the sequence or add trailing N before translation. This may become an error in future.\n",
      "  BiopythonWarning)\n"
     ]
    }
   ],
   "source": [
    "# Next step we want to compare the two databases\n",
    "# The resfinder database is now encapsulated in the resfinder_db dictionary\n",
    "# The card database is now encapsuled in card_dict\n",
    "\n",
    "# Now to compare these two we are going to do the following.\n",
    "# 1. translate resfinder_db sequences\n",
    "# 2. compare the protein sequences from the two databases.\n",
    "# 3. give each unique protein sequence a unique id.\n",
    "# 4. Identify whether DNA variants are the same or different\n",
    "\n",
    "# Note all elements of each database are disctinct (we have removed duplicates as part of formatting)\n",
    "\n",
    "\n",
    "# First we start with a function to compare two proteins\n",
    "def compare_2_prots(s1, s2):\n",
    "    # Now as there is a bit of a wiggle around what sequence is at \n",
    "    s1_poss = [s1,s1[1:],s1[:-1],s1[1:-1]]\n",
    "    s2_poss = [s2,s2[1:],s2[:-1],s2[1:-1]]\n",
    "    linked = False\n",
    "    for k in s1_poss:\n",
    "        if k in s2_poss:\n",
    "            linked = True\n",
    "    return linked\n",
    "\n",
    "# Next lets get all of the proteins from both the CARD and Resfinder databases\n",
    "resfinder_prots = {}\n",
    "for k in resfinder_db:\n",
    "    resfinder_prots[k] = str(resfinder_db[k].seq.translate(11))\n",
    "\n",
    "card_prots = {}\n",
    "for k in card_dict:\n",
    "    card_prots[k] = card_dict[k]['prot_seq']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now we combine these into a list of individual proteins\n",
    "prot_list = []\n",
    "for k in resfinder_prots:\n",
    "    seen_before  = False\n",
    "    for j in prot_list:\n",
    "        if compare_2_prots(resfinder_prots[k], j) == True:\n",
    "            seen_before = True\n",
    "    if seen_before == False:\n",
    "        prot_list.append(resfinder_prots[k])\n",
    "    \n",
    "for k in card_prots:\n",
    "    seen_before = False\n",
    "    for j in prot_list:\n",
    "        if compare_2_prots(card_prots[k], j) == True:\n",
    "            seen_before = True\n",
    "    if seen_before == False:\n",
    "        prot_list.append(card_prots[k])\n",
    "\n",
    "#Turning these into a dictionary\n",
    "prots_full = {}\n",
    "prot_no = 1\n",
    "for k in prot_list:\n",
    "    prot_id = \"uprotein_{0}\".format(prot_no)\n",
    "    prots_full[prot_id] = k\n",
    "    prot_no += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we want to make an output which combines all of these.\n",
    "# We will produce two however, \n",
    "# 1 which only contains the simple names linking (and official names) (CSV) and 1 which contains all of the details about the sequence (JSON)\n",
    "\n",
    "final_dict = {}\n",
    "with open(\"db_comparison.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"prot_id\", 'card_fids','card_oids', 'resfinder_fids', 'resfinder_oids'])\n",
    "    for k in prots_full:\n",
    "        final_dict[k] ={\"card\":{}, \"resfinder\":{}}\n",
    "        k_card_ids = []\n",
    "        k_resfinder_ids = []\n",
    "        for j in card_prots:\n",
    "            if compare_2_prots(prots_full[k], card_prots[j]) == True:\n",
    "                k_card_ids.append(j)\n",
    "        k_card_origid = [card_dict[j]['orig_id'] for j in k_card_ids]\n",
    "        for j in k_card_ids:\n",
    "            final_dict[k]['card'][j] = card_dict[j]\n",
    "        for j in resfinder_prots:\n",
    "            if compare_2_prots(prots_full[k], resfinder_prots[j]) == True:\n",
    "                k_resfinder_ids.append(j)\n",
    "        for j in k_resfinder_ids:\n",
    "            final_dict[k]['resfinder'][j] = {resfinder_db[j].id:str(resfinder_db[j].seq)}\n",
    "        k_resfinder_origid = [resfinder_db[j].id for j in k_resfinder_ids]\n",
    "        csv_line = [k, \":\".join(k_card_ids),\":\".join(k_card_origid), \n",
    "                   \":\".join(k_resfinder_ids), \":\".join(k_resfinder_origid)]\n",
    "        writer.writerow(csv_line)\n",
    "\n",
    "\n",
    "with open(\"db_comparison_full.csv\", \"w\") as f:\n",
    "    x = json.dumps(final_dict)\n",
    "    json.dump(x, f) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note I will only investigate differences between the two that I encounter in my data., \n",
    "# so the next step will be to compare the output between CARD and Resfinder.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
