{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: blue;\">Intro</span>\n",
    "\n",
    "The first part of the analysis is to see what happens when ABRicate is run with both the Resfinder and CARD database to identify the extent of difference in how each method identifies \"TRANSMISSIBLE RESISTANCE GENES\"\n",
    "Note by the fact we are only looking at \"TRANSMISSIBLE RESISTNACE GENES\" CARD and Resfinder dbs should have all necessary genes in them\n",
    "\n",
    "**For two programs to identify the same thing they have to identify everything identically at the protein level**\n",
    "\n",
    "### Setup \n",
    "\n",
    "**Dependencies**\n",
    "* Python 3\n",
    "* Biopython\n",
    "\n",
    "**Inputs - Resistance Databases**\n",
    "* resfinder_20191001 (Primary)\n",
    "* card_20191023\n",
    "* resfinder_20180122\n",
    "* resfinder_20170126\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mcard_20191023\u001b[m\u001b[m/                      \u001b[1m\u001b[36mresfinder_20180122\u001b[m\u001b[m/\r\n",
      "card_20191023_formatted.fasta       \u001b[1m\u001b[36mresfinder_20190122\u001b[m\u001b[m/\r\n",
      "card_20191023_link.csv              \u001b[1m\u001b[36mresfinder_20191001\u001b[m\u001b[m/\r\n",
      "db_comparison.csv                   \u001b[1m\u001b[36mresfinder_20191001_ami\u001b[m\u001b[m/\r\n",
      "db_comparison_full.json             \u001b[1m\u001b[36mresfinder_20191001_blm\u001b[m\u001b[m/\r\n",
      "\u001b[1m\u001b[36mdb_comparison_result_tarballs\u001b[m\u001b[m/      resfinder_20191001_formatted.fasta\r\n",
      "db_related.ipynb                    resfinder_20191001_link.csv\r\n",
      "formatting_old_resfinder_dbs.ipynb  \u001b[1m\u001b[36mresfinder_20191001_qui\u001b[m\u001b[m/\r\n",
      "resfinder.fasta                     \u001b[1m\u001b[36mresfinder_20191001_sul\u001b[m\u001b[m/\r\n",
      "\u001b[1m\u001b[36mresfinder_20170126\u001b[m\u001b[m/                 \u001b[1m\u001b[36mresfinder_20191001_tri\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "# Importing modules and looking at local files\n",
    "\n",
    "# Python inbuilt\n",
    "import json\n",
    "import csv\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Extra downloaded\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "# Data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# File Structure\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we PARSE the databases \n",
    "# CARD\n",
    "card_db = \"card_20191023/card-data/card.json\"\n",
    "with open(card_db) as f:\n",
    "    card_db = json.load(f)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: blue;\">Formatting and comparing the two databases</span>\n",
    "\n",
    "\n",
    "So for comparing CARD with Resfinder results, were aiming to identify transmissible proteins from each\n",
    "In card this approximately equates to the **protein homolog model**.\n",
    "\n",
    "This process has several steps\n",
    "1. For each database, create a csv which contains an easily accesible set of information for comparison\n",
    "- Note for working out whether there is a translation link, we translate with translation table 11, then disregard the first element and remove any trailing stop codon sequence.\n",
    "- Looking at the remaining sequence, if they match then there is a link, if not no link\n",
    "- If no link leave blank, and each DNA with no link will be put next to its directly translated protein\n",
    "2. As part of making a database each element will get a new identifier which will be used to make sure all programs can process them the same way\n",
    "- e.g. cardnewid_x \n",
    "2. Match these CSVs according to protein sequence\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### The card CSV will have the following headers\n",
    "\n",
    "1. prot_seq\n",
    "2. dna_seq\n",
    "3. card_name\n",
    "4. card_newname\n",
    "5. aro_id\n",
    "6. translation_link\n",
    "\n",
    "#### The resfinder CSV will have the following headers\n",
    "\n",
    "1. prot_seq\n",
    "2. dna_seq\n",
    "3. resfinder_name\n",
    "4. resfinder_newname\n",
    "\n",
    "\n",
    "#### DATABASE QUALITY CONTROL\n",
    "\n",
    "For each database, we need to create a unique identifier for elements\n",
    "This based on its DNA sequence only\n",
    "This in effect will remove a sequence which has the same DNA sequence but different name in any given database\n",
    "\n",
    "e.g. supposed the following sequence AACTTGCTA was called both gene1 and gene2 in the formated databases it will only be called newgene1\n",
    "\n",
    "Duplicates names for different sequences will be asigned new names. The aim of this approach is to retain the databases in as close to original format as possible , while making up to date databases readable for each of the 4 programs\n",
    "\n",
    "##### Resfinder 1st October 2019 release\n",
    "\n",
    "**Note the resfinder database is produced by concatinating each of the specific antibiotic databases, this results in some duplicates which we remove, (i.e. the genes which affect more than one type of antibiotic, (for example quinolone resistance causing aac variant)**\n",
    "\n",
    "###### Removed variants below\n",
    "\n",
    "So the duplicate names we will have censored using this method\n",
    "1. \"blaOXA-347_1_JN086160\" , same sequence as \"blaOXA-347_1_ACWG01000053\" (2 refs)\n",
    "2. \"blaZ_129_CP003194\", same sequence as \"blaZ_125_CP003194\" (curation)\n",
    "3. \"blaIMP-58_1_KU647281\",  same sequence as \"blaIMP-58_1_KU647281\" (duplciate)\n",
    "4. \"blaCTX-M-63_1_AB205197\", same sequence as \"blaCTX-M-63_1_EU660216\" (2 refs)\n",
    "5. \"blaCMY-110_1_AB872957\", same sequence as \"blaCMY-110_1_AB872957\" (duplicate)\n",
    "6. \"blaCMY-104_1_KF150216\", same sequence as \"blaCMY-104_1_KF150216\" (duplicate)\n",
    "7. \"blaACC-4_2_EF504260\", same sequence as \"blaACC-4_1_GU256641\" (2 refs)\n",
    "8. \"blaSHV-36_1_AF467947\", same sequence as \"blaSHV-36_1_AF467947\" (duplicate)\n",
    "9. \"blaOXA-60_1_AF525303\", same sequence as \"blaOXA-60_1_AF525303\" (duplicate)\n",
    "10. \"blaFRI-1_1_KT192551\", same sequence as \"blaFRI-1_1_KT192551\" (duplicate)\n",
    "11. \"cfr_1_AM408573\", same sequence as \"cfr_1_AM408573\" (duplicate)\n",
    "12. \"cfr_2_AJ879565\", same sequence as \"cfr_2_AJ879565\" (duplicate)\n",
    "13. \"cfr(B)_3_KR610408\", same sequence as \"cfr(B)_3_KR610408\" (duplicate)\n",
    "14. aac(6')-Ib-cr_1_DQ303918, same sequence as \"aac(6')-Ib-cr_1_DQ303918\" (duplicate)\n",
    "15. aac(6')-Ib-cr_2_EF636461 , same sequence as \"aac(6')-Ib-cr_2_EF636461\" (duplicate)\n",
    "16. dfrA22_3_FM957884, same sequence as dfrA33_1_FM957884 (curation)\n",
    "\n",
    "##### CARD 23rd October 2019 release\n",
    "\n",
    "This database is more complex in structure, but to attempt to produce a similar set of genes (i.e. just the transmissible genes) we only look at the genes which apply to the \"protein homolog model\"\n",
    "\n",
    "In this database, there are several things to note which will be important as we compare the database:\n",
    "* Each element has at least one DNA and protein sequence\n",
    "* all of the DNA elements do translate to produce the related protein , but there is an issue with wether or not sequences include a stop codon and how the start codon is translated. Also some are not in the correct frame\n",
    "* Also 1 sequence (Erm(44)v) has 2 sequences. This is not relavent to this study as it focusses on E. coli whereas this gene is only seen in S. saprophyticus and encodes macrolide resistance (to which E. coli is innately resistant)\n",
    "* For simplicity here, we will just take the DNA sequences from the protein homolog CARD.\n",
    "* Otherwise sequences in this database are all unique (see Resfinder Issues above)\n",
    "\n",
    "\n",
    "#### DATABASE PREPARATION CHOICES\n",
    "\n",
    "This is any specific parameters we have chosen in preparing databases\n",
    "\n",
    "**ARIBA -> Non coding only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2617"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CARD\n",
    "\n",
    "# This code makes the formatted card db (\"card_20191023_formatted.fasta\") \n",
    "# and produces a key for the identifiers in the fasta file \"card_20191023_link.csv\"\n",
    "# And finally produces a dictionary which we use downstream \"card_20191023_link.csv\"\n",
    "\n",
    "card_formatted_no = 1\n",
    "\n",
    "card_dict = {}\n",
    "\n",
    "card_recs = []\n",
    "\n",
    "with open(\"card_20191023_link.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    for key in card_db.keys():\n",
    "        try:\n",
    "            # First we extract relavent data\n",
    "            if card_db[key]['model_type'] == \"protein homolog model\":\n",
    "                aro_id = card_db[key]['ARO_accession']\n",
    "                name = card_db[key][\"ARO_name\"]\n",
    "                for k in card_db[key]['model_sequences']['sequence'].values():\n",
    "                    card_prot = k['protein_sequence']['sequence']\n",
    "                    card_dna = k['dna_sequence']['sequence']\n",
    "                # This way we automatically keep the second sequence\n",
    "                # Then we rename things so that each program formatts them properly.\n",
    "                new_id = \"cardnewid_{0}\" .format(card_formatted_no)\n",
    "                card_formatted_no += 1\n",
    "                card_seq = Seq(card_dna)\n",
    "                card_rec = SeqRecord(card_seq, id=new_id, description=\"\")\n",
    "                card_recs.append(card_rec)\n",
    "                # Now we want to create some stuff for a linking database to compare the two\n",
    "                orig_id = name + \"_ARO\"+ aro_id\n",
    "                card_dict[new_id] = {\"orig_id\":orig_id, \n",
    "                                    \"dna_seq\":card_dna,\n",
    "                                    \"prot_seq\":card_prot}\n",
    "                writer.writerow([orig_id, new_id, str(card_seq)])\n",
    "        except:\n",
    "            # This line removes the 1 entry which just has a description of the database\n",
    "            pass\n",
    "\n",
    "SeqIO.write(card_recs, \"card_20191023_formatted.fasta\", \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3079"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resfinder\n",
    "\n",
    "# Likewise for the resfinder database\n",
    "# The formatted fasta \"resfinder_20191001_formatted.fasta\"\n",
    "# link for ids \"resfinder_20191001_link.csv\"\n",
    "# Dictionary for downstream analysis resfinder_db\n",
    "\n",
    "# Firstly, you concatenate and read in the database\n",
    "\n",
    "##############################################################################\n",
    "# NOTE THIS NEEDS TO BE FIXED BEFORE WE PUT THIS UP FORMALLY ONLINE\n",
    "if os.name == \"posix\":\n",
    "    subprocess.check_call(\"cat resfinder_20191001/*.fsa > resfinder.fasta\", shell=True)\n",
    "else:\n",
    "    pass\n",
    "resfinder_initdb = SeqIO.parse(\"resfinder_20191001/resfinder.fasta\", \"fasta\")\n",
    "##############################################################################\n",
    "\n",
    "# Then you assign a new unique name to each element of the database\n",
    "# Note some elements are removed (see above) to ensure each DNA sequence only has one name\n",
    "# The way things are linked are put into a resfinder_20191001_link.csv file\n",
    "# The final database is then written into a resfinder_20191001_formatted.fasta\n",
    "resfinder_db = {}\n",
    "identified_seqs = []\n",
    "newid = 0\n",
    "for k in resfinder_initdb:\n",
    "    if str(k.seq) not in identified_seqs:\n",
    "        newid += 1\n",
    "        identified_seqs.append(str(k.seq))\n",
    "        resfinder_db[\"resfindernewid_{0}\" .format(newid)] = k\n",
    "out_recs = []\n",
    "with open(\"resfinder_20191001_link.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f, delimiter = \",\")\n",
    "    for k in resfinder_db:\n",
    "        writer.writerow([k, resfinder_db[k].id, str(resfinder_db[k].seq)])\n",
    "        k_id = k\n",
    "        k_desc = \"\"\n",
    "        k_seq = resfinder_db[k].seq\n",
    "        k_rec = SeqRecord(k_seq, id=k_id, description=k_desc)\n",
    "        out_recs.append(k_rec)\n",
    "\n",
    "SeqIO.write(out_recs, \"resfinder_20191001_formatted.fasta\", \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: blue;\">Next comes how to format the databases </span>\n",
    "\n",
    "This code basically goes through the exact commands we use to format the databases for each program. Note for each one we using singularity images which contain each program. Your actual locations of some script (e.g. the SRST2 specific ones)  may vary\n",
    "\n",
    "As an additional side point this database then needs to be formatted to meet ABRicate's structure\n",
    "The script below does this\n",
    "\n",
    "~~~\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "base_db = SeqIO.parse(\"<db_file>\",\"fasta\")\n",
    "abricate_recs = []\n",
    "\n",
    "for k in base_db:\n",
    "    k_seq = k.seq\n",
    "    k_id = \"resfinderformatted~~~{0}~~~00{1}\".format(k.id, \"{:04d}\" .format(int(k.id.split(\"_\")[-1])))\n",
    "    k_rec = SeqRecord(k_seq, id=k_id, description=\"\")\n",
    "    abricate_recs.append(k_rec)\n",
    "SeqIO.write(abricate_recs, \"sequences\", \"fasta\")\n",
    "~~~\n",
    "\n",
    "\n",
    "##### Each of the following illustrates the steps required to prep the database\n",
    "\n",
    "**preparing the ABRicate_db**\n",
    "\n",
    "~~~\n",
    "python abricate_format.py \n",
    "mkdir abricate_db\n",
    "mv sequences abricate_db/\n",
    "cd abricate_db\n",
    "makeblastdb -in sequences -title <db_title> -dbtype nucl -hash_index\n",
    "cd ..\n",
    "~~~\n",
    "**preparing the ARIBA db**\n",
    "~~~\n",
    "ariba prepareref --all_coding no -f <db_file> ariba_db\n",
    "~~~\n",
    "\n",
    "**Preparing the KmerResistance db**\n",
    "** Note for KmerResistance, there is an additional file**\n",
    "### add to this text ### should primarily been in the supplements\n",
    "\n",
    "The exception to this was that KmerResistance requires a “bacteria.fsa” FASTA file of all complete genomes in NCBI’s RefSeq database to filter low-coverage matches. As of writing, the version used by KmerResistance’s authors was not publicly available, however we attempted mitigate this using two alterations; replacing the file using a FASTA containing all complete genomes as identified by Centrifuge-download[14], and applying an average depth of coverage cut-off of >5x to KmerResistance results. For ABRicate (which uses BLASTn to search assemblies), assemblies were produced using SPAdes[8] run with default parameters. \n",
    "\n",
    "~~~\n",
    "mkdir kmerres_db\n",
    "mv bacteria.fsa kmerres_db\n",
    "cp <db_file> kmerres_db/\n",
    "cd kmerres_db\n",
    "kma index -i bacteria.fsa -o bacteria -Sparse ATG\n",
    "mv <db_file> kmerres_fasta.fa\n",
    "kma_index -i kmerres_fasta.fa -o kmerres_fasta\n",
    "cd ..\n",
    "~~~\n",
    "\n",
    "**Preparing the SRST2 db**\n",
    "~~~\n",
    "mkdir srst2_db\n",
    "cd srst2_db/\n",
    "mv <db_file> rawseqs.fasta\n",
    "cd-hit-est -i rawseqs.fasta -o rawseqs_cdhit90 -d 0 > rawseqs_cdhit90.stdout\n",
    "python /srst2/database_clustering/cdhit_to_csv.py --cluster_file rawseqs_cdhit90.clstr --infasta rawseqs.fasta --outfile rawseqs_clustered.csv\n",
    "python /srst2/database_clustering/csv_to_gene_db.py -t rawseqs_clustered.csv -o seqs_clustered.fasta -f rawseqs.fasta -c 4\n",
    "cd ..\n",
    "~~~\n",
    "\n",
    "** A similar method is used for preparing the card and legacy resfinder databases **\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: blue;\">Comparing the databases</span>\n",
    "\n",
    "Next step we want to compare the two databases\n",
    "The resfinder database is now encapsulated in the resfinder_db dictionary\n",
    "The card database is now encapsuled in card_dict\n",
    "\n",
    "**Now to compare these two we are going to do the following.**\n",
    "1. translate resfinder_db sequences\n",
    "2. compare the protein sequences from the two databases. [note this requires some wiggle room re first and last amino-acids, see above]\n",
    "3. give each unique protein sequence a unique id.\n",
    "4. Identify whether DNA variants are the same or different\n",
    "\n",
    "**Note all elements of each database are disctinct (we have removed duplicates as part of formatting)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timdavies/anaconda/lib/python3.6/site-packages/Bio/Seq.py:2715: BiopythonWarning: Partial codon, len(sequence) not a multiple of three. Explicitly trim the sequence or add trailing N before translation. This may become an error in future.\n",
      "  BiopythonWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** EXCLUDED NEARLY UBIQUITOUS SEQUENCES ******\n",
      "['mdtP', 'gadX', 'mdtF', 'cpxA', 'mdtH', 'mdtA', 'AcrS', 'emrY', 'mdtG', 'emrK', 'eptA', 'mdtB', 'TolC', 'CRP', 'ugd', 'baeS', 'evgA', 'acrB', 'mdtM', 'H-NS', 'mdtC', 'evgS', 'emrR', 'baeR', 'acrD', 'AcrF', 'mdtN', 'AcrE', 'mphB', 'emrA', 'bacA', 'emrB', 'mdtE', 'marA', 'mdtO', 'Escherichia coli ampC1 beta-lactamase', 'PmrF', 'Escherichia coli ampH beta-lactamase', 'kdpE', 'msbA', 'YojI', 'Escherichia coli emrE', 'Escherichia coli acrA', 'Escherichia coli mdfA', 'Escherichia coli ampC beta-lactamase', 'Klebsiella pneumoniae KpnE', 'Klebsiella pneumoniae KpnF']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# First we start with a function to compare two proteins with \"wiggle room\"\n",
    "def compare_2_prots(s1, s2):\n",
    "    # Now as there is a bit of a wiggle around what sequence is at \n",
    "    s1_poss = [s1,s1[1:],s1[:-1],s1[1:-1]]\n",
    "    s2_poss = [s2,s2[1:],s2[:-1],s2[1:-1]]\n",
    "    linked = False\n",
    "    for k in s1_poss:\n",
    "        if k in s2_poss:\n",
    "            linked = True\n",
    "    return linked\n",
    "\n",
    "# Next lets get all of the proteins from both the CARD and Resfinder databases\n",
    "resfinder_prots = {}\n",
    "for k in resfinder_db:\n",
    "    resfinder_prots[k] = str(resfinder_db[k].seq.translate(11))\n",
    "\n",
    "card_prots = {}\n",
    "for k in card_dict:\n",
    "    card_prots[k] = card_dict[k]['prot_seq']\n",
    "\n",
    "\n",
    "# Now we combine these into a list of individual proteins\n",
    "prot_list = []\n",
    "for k in resfinder_prots:\n",
    "    seen_before  = False\n",
    "    for j in prot_list:\n",
    "        if compare_2_prots(resfinder_prots[k], j) == True:\n",
    "            seen_before = True\n",
    "    if seen_before == False:\n",
    "        prot_list.append(resfinder_prots[k])\n",
    "    \n",
    "for k in card_prots:\n",
    "    seen_before = False\n",
    "    for j in prot_list:\n",
    "        if compare_2_prots(card_prots[k], j) == True:\n",
    "            seen_before = True\n",
    "    if seen_before == False:\n",
    "        prot_list.append(card_prots[k])\n",
    "\n",
    "#Turning these into a dictionary\n",
    "prots_full = {}\n",
    "prot_no = 1\n",
    "for k in prot_list:\n",
    "    prot_id = \"uprotein_{0}\".format(prot_no)\n",
    "    prots_full[prot_id] = k\n",
    "    prot_no += 1\n",
    "\n",
    "# We then want to make an output which combines all of these.\n",
    "# We will produce two however, \n",
    "# 1 which only contains the simple names linking (and official names) (CSV) and 1 which contains all of the details about the sequence (JSON)\n",
    "\n",
    "final_dict = {}\n",
    "with open(\"db_comparison.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"prot_id\", 'card_fids','card_oids', 'resfinder_fids', 'resfinder_oids'])\n",
    "    for k in prots_full:\n",
    "        final_dict[k] ={\"card\":{}, \"resfinder\":{}, \"protein\":prots_full[k]}\n",
    "        k_card_ids = []\n",
    "        k_resfinder_ids = []\n",
    "        for j in card_prots:\n",
    "            if compare_2_prots(prots_full[k], card_prots[j]) == True:\n",
    "                k_card_ids.append(j)\n",
    "        k_card_origid = [card_dict[j]['orig_id'] for j in k_card_ids]\n",
    "        for j in k_card_ids:\n",
    "            final_dict[k]['card'][j] = card_dict[j]\n",
    "        for j in resfinder_prots:\n",
    "            if compare_2_prots(prots_full[k], resfinder_prots[j]) == True:\n",
    "                k_resfinder_ids.append(j)\n",
    "        for j in k_resfinder_ids:\n",
    "            final_dict[k]['resfinder'][j] = {resfinder_db[j].id:str(resfinder_db[j].seq)}\n",
    "        k_resfinder_origid = [resfinder_db[j].id for j in k_resfinder_ids]\n",
    "        csv_line = [k, \":\".join(k_card_ids),\":\".join(k_card_origid), \n",
    "                   \":\".join(k_resfinder_ids), \":\".join(k_resfinder_origid)]\n",
    "        writer.writerow(csv_line)\n",
    "\n",
    "# NOTE FOR ME, see sublime_text on problems with 3 SHV sequences. I will currently plough on regardless \n",
    "        \n",
    "with open(\"db_comparison_full.json\", \"w\") as f:\n",
    "    x = json.dumps(final_dict)\n",
    "    json.dump(x, f) \n",
    "\n",
    "# Lastly given the different scope of the two databases, CARD will contain some sequences that are ubiquitous in E. coli\n",
    "# We create a list of thee so thay can be filtered out at a later stage.\n",
    "\n",
    "# We do this by examining the card_prevalence.txt from the card database. (note for this study we have used the 20191127 release)\n",
    "# and I set a rather arbitrary threshold of 90% to determine near ubiquity\n",
    "\n",
    "def near_ubiquitous(l):\n",
    "    return([k for k in l if k > 50] != [])\n",
    "\n",
    "# so we go through all the sequences in the card protein homolog database and then check whether they are nearly ubuqitously found in E. coli\n",
    "# card exclusion list and then a human interpretable version\n",
    "nu_ecoli_card = []\n",
    "nu_ecoli_card_hi = []\n",
    "# We will also check we won't remove any Resfinder ones as its our default method\n",
    "nu_ecoli_rf = []\n",
    "\n",
    "# Reloading the data\n",
    "db_comparison = pd.read_csv(\"db_comparison.csv\").fillna(\"\")\n",
    "card_prev = pd.read_csv(\"card_prevalence_20191127.txt\", delimiter = \"\\t\", index_col = 0)\n",
    "card_prev = card_prev.loc[card_prev.Pathogen == \"Escherichia coli\"]\n",
    "for i in range(len(db_comparison)):\n",
    "    if db_comparison.iloc[i].card_fids != \"\":\n",
    "        i_card_id = db_comparison.iloc[i].card_fids\n",
    "        i_rf_id = db_comparison.iloc[i].resfinder_fids\n",
    "        i_name = db_comparison.iloc[i].card_oids.split(\"_\")[0]\n",
    "        i_aro = \"ARO:\" + db_comparison.iloc[i].card_oids.split(\"_\")[-1].lstrip(\"ARO\")\n",
    "        try:\n",
    "            i_prev = card_prev.loc[[i_aro]]\n",
    "            i_ncbi_wgs = list(i_prev['NCBI WGS'])\n",
    "            if near_ubiquitous(i_ncbi_wgs) == True:\n",
    "                nu_ecoli_card.append(i_card_id)\n",
    "                nu_ecoli_card_hi.append(i_name)\n",
    "                if i_rf_id != \"\":\n",
    "                    for j in i_rf_id.split(\":\"):\n",
    "                        nu_ecoli_rf.append(i_rf_id)\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "# having generated these lists \n",
    "# We check the  resfinder list is empty (NOTE AS WE GO THROUGH THE DB COMPARISON DATABASE IT WILL REMOVE ANY RESFINDER SEQUENCES WITH THE SAME PROTEIN)\n",
    "assert nu_ecoli_rf == []\n",
    "# then print the card exclusions\n",
    "print(\"***** EXCLUDED NEARLY UBIQUITOUS SEQUENCES ******\")\n",
    "print(nu_ecoli_card_hi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: blue;\">Comparing Resfinder and CARD output</span>\n",
    "\n",
    "Note I will only investigate differences between the two that I encounter in my data., \n",
    "so the next step will be to compare the output between CARD and Resfinder.\n",
    "\n",
    "This bit needs to be updated, given the figure I intend to produce? compare all full databases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "#               LOADING THE DATA                            #\n",
    "#############################################################\n",
    "\n",
    "# Note during the covid outbreak I have created a temporary file structure to enable analysis of files\n",
    "# This option (if true) enables using it\n",
    "temp = False\n",
    "# THIS CHOICE WILL BE DELETED PRIOR TO PRE_PRINT publication\n",
    "\n",
    "result_dict = {}\n",
    "\n",
    "linking_csv = pd.read_csv(\"db_comparison.csv\", index_col=0).fillna(\"\")\n",
    "card_linkdict = {}\n",
    "card_names = {}\n",
    "for k in linking_csv.index:\n",
    "    for j in range(len(linking_csv.loc[k].card_fids.split(\":\"))):\n",
    "        j_fid = linking_csv.loc[k].card_fids.split(\":\")[j]\n",
    "        j_oid = linking_csv.loc[k].card_oids.split(\":\")[j]        \n",
    "        card_linkdict[j_fid] = k\n",
    "        card_names[k] = j_oid\n",
    "        \n",
    "resfinder_linkdict = {}\n",
    "resfinder_names = {}\n",
    "for k in linking_csv.index:\n",
    "    for j in range(len(linking_csv.loc[k].resfinder_fids.split(\":\"))):\n",
    "        j_fid = linking_csv.loc[k].resfinder_fids.split(\":\")[j]\n",
    "        j_oid = linking_csv.loc[k].resfinder_oids.split(\":\")[j]\n",
    "        resfinder_linkdict[j_fid]=k\n",
    "        resfinder_names[k]=j_oid\n",
    "\n",
    "card_ftranslate = pd.read_csv(\"card_20191023/card_20191023_link.csv\", header=None, index_col = 1)\n",
    "card_ftranslate = {k: card_ftranslate.loc[k][0] for k in card_ftranslate.index}\n",
    "card_btranslate = pd.read_csv(\"card_20191023/card_20191023_link.csv\", header=None, index_col = 0)\n",
    "card_btranslate = {k: card_btranslate.loc[k][1] for k in card_btranslate.index}\n",
    "resfinder_ftranslate = pd.read_csv(\"resfinder_20191001/resfinder_20191001_link.csv\", header=None, index_col = 1)\n",
    "resfinder_ftranslate = {k: resfinder_ftranslate.loc[k][0] for k in resfinder_ftranslate.index}\n",
    "resfinder_btranslate = pd.read_csv(\"resfinder_20191001/resfinder_20191001_link.csv\", header=None, index_col = 0)\n",
    "resfinder_btranslate = {k: resfinder_btranslate.loc[k][1] for k in resfinder_btranslate.index}\n",
    "\n",
    "card_dir = \"db_comparison_result_tarballs/card_results/\"\n",
    "card_reports = [os.path.join(root, f) for root, dirs, files in os.walk(card_dir) for f in files]\n",
    "rf_dir = \"db_comparison_result_tarballs/resfinder_results/\"\n",
    "rf_reports = [os.path.join(root, f) for root, dirs, files in os.walk(rf_dir) for f in files]\n",
    "guuids = [k.split(\"/\")[-1].split(\"_\")[0] for k in rf_reports if \"summary\" not in k]\n",
    "result_dict = {k:{\"card\":\"\", \"resfinder\":\"\"} for k in guuids}\n",
    "for k in result_dict:\n",
    "    card_fl = [f for f in card_reports if k in f]\n",
    "    assert len(card_fl) == 1\n",
    "    card_fl = card_fl[0]\n",
    "    resfinder_fl = [f for f in rf_reports if k in f]\n",
    "    assert len(resfinder_fl) == 1 \n",
    "    resfinder_fl = resfinder_fl[0]\n",
    "    result_dict[k][\"card\"] = card_fl\n",
    "    result_dict[k][\"resfinder\"] = resfinder_fl\n",
    "\n",
    "### DELETE THIS SECTION FOR pre-print publication\n",
    "\n",
    "# this code essentially produces a dictionary where keys are guuids and then within that \n",
    "# there is a card and a resfinder reports\n",
    "\n",
    "if temp == True:\n",
    "    card_dir = \"../../../result_tarballs/pl_comp_data/db_comparison_result_tarballs/card_results\"\n",
    "    card_reports = [os.path.join(root, f) for root, dirs, files in os.walk(card_dir) for f in files]\n",
    "    rf_dir = \"../../../result_tarballs/pl_comp_data/db_comparison_result_tarballs/resfinder_results\"\n",
    "    rf_reports = [os.path.join(root, f) for root, dirs, files in os.walk(rf_dir) for f in files]\n",
    "    guuids = [k.split(\"\\\\\")[-1].split(\"_\")[0] for k in rf_reports if \"summary\" not in k]\n",
    "    result_dict = {k:{\"card\":\"\", \"resfinder\":\"\"} for k in guuids}\n",
    "    for k in result_dict:\n",
    "        card_fl = [f for f in card_reports if k in f]\n",
    "        assert len(card_fl) == 1\n",
    "        card_fl = card_fl[0]\n",
    "        resfinder_fl = [f for f in rf_reports if k in f]\n",
    "        assert len(resfinder_fl) == 1 \n",
    "        resfinder_fl = resfinder_fl[0]\n",
    "        result_dict[k][\"card\"] = card_fl\n",
    "        result_dict[k][\"resfinder\"] = resfinder_fl\n",
    "\n",
    "    \n",
    "### END OF DELETE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class isolate:\n",
    "    \n",
    "    def __init__(self, guuid):\n",
    "        self.guuid = guuid\n",
    "        self.resfinder_fl = pd.read_csv(result_dict[self.guuid][\"resfinder\"], \"\\t\")\n",
    "        self.resfinder_trgs = sorted(list(set([resfinder_linkdict[k] for k in list(self.resfinder_fl[\"GENE\"])])))\n",
    "        self.card_fl = pd.read_csv(result_dict[self.guuid][\"card\"], \"\\t\")\n",
    "        self.card_trgs = sorted(list(set([card_linkdict[k] for k in list(self.card_fl[\"GENE\"]) \n",
    "                                          if k not in nu_ecoli_card])))\n",
    "        self.resfinder_otrgs = [resfinder_names[k] for k in self.resfinder_trgs]\n",
    "        self.card_otrgs = [card_names[k] for k in self.card_trgs]\n",
    "\n",
    "\n",
    "out_genes = []\n",
    "for g in guuids:\n",
    "    x = isolate(g)\n",
    "    for k in x.resfinder_otrgs:\n",
    "        out_genes.append(k)\n",
    "x = sorted(list(set(out_genes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARR-3_4_FM207631\n",
      "aac(3)-IIa_1_X51534\n",
      "aac(3)-IId_1_EU022314\n",
      "aac(3)-IVa_1_X01385\n",
      "aac(3)-Ia_1_X15852\n",
      "aac(3)-Ib_1_L06157\n",
      "aac(3)-VIa_2_NC_009838\n",
      "aac(6')-Ib-cr_1_DQ303918\n",
      "aac(6')-Ib_1_M21682\n",
      "aac(6')-Ib_2_M23634\n",
      "aadA12_1_AY665771\n",
      "aadA13_1_AY713504\n",
      "aadA1_2_FJ591054\n",
      "aadA1_3_JQ414041\n",
      "aadA1_4_JQ480156\n",
      "aadA22_1_AM261837\n",
      "aadA2_1_NC_010870\n",
      "aadA2_2_JQ364967\n",
      "aadA3_1_AF047479\n",
      "aadA4_1_Z50802\n",
      "aadA5_1_AF137361\n",
      "aadA8b_2_AM040708\n",
      "ant(2'')-Ia_1_X04555\n",
      "ant(2'')-Ia_6_AJ871915\n",
      "ant(3'')-Ia_1_X02340\n",
      "ant(3'')-Ii-aac(6')-IId_1_AF453998\n",
      "aph(3'')-Ib_1_M28829\n",
      "aph(3'')-Ib_3_AF321550\n",
      "aph(3'')-Ib_4_AF313472\n",
      "aph(3'')-Ib_5_AF321551\n",
      "aph(3')-IIa_2_V00618\n",
      "aph(3')-Ia_1_V00359\n",
      "aph(3')-Ia_3_EF015636\n",
      "aph(3')-Ia_4_AF498082\n",
      "aph(3')-Ia_6_L05392\n",
      "aph(3')-Ia_7_X62115\n",
      "aph(3')-VI_1_KC170992\n",
      "aph(4)-Ia_1_V01499\n",
      "aph(6)-Ic_1_X01702\n",
      "aph(6)-Id_1_M28829\n",
      "aph(6)-Id_4_CP000971\n",
      "armA_1_AY220558\n",
      "blaACT-15_1_JX440356\n",
      "blaCARB-2_1_M69058\n",
      "blaCMY-2_1_X91840\n",
      "blaCMY-37_1_AB280919\n",
      "blaCMY-42_1_HM146927\n",
      "blaCMY-4_1_LNHZ01000079\n",
      "blaCMY-51_1_JQ733571\n",
      "blaCMY-6_1_AJ011293\n",
      "blaCMY-70_1_JX440350\n",
      "blaCTX-M-139_1_KC107824\n",
      "blaCTX-M-14b_1_DQ359215\n",
      "blaCTX-M-15_1_AY044436\n",
      "blaCTX-M-189_1_FJ657512\n",
      "blaCTX-M-1_1_DQ915955\n",
      "blaCTX-M-27_1_AY156923\n",
      "blaCTX-M-3_1_Y10278\n",
      "blaCTX-M-55_1_DQ810789\n",
      "blaCTX-M-9_1_AF174129\n",
      "blaDHA-1_1_Y16410\n",
      "blaIMP-70_1_MG748725\n",
      "blaKPC-2_1_AY034847\n",
      "blaNDM-1_1_FN396876\n",
      "blaNDM-5_1_JN104597\n",
      "blaNDM-7_1_JX262694\n",
      "blaOXA-181_1_CM004561\n",
      "blaOXA-1_1_HQ170510\n",
      "blaOXA-244_1_KP659189\n",
      "blaOXA-2_1_DQ112222\n",
      "blaOXA-48_1_AY236073\n",
      "blaOXA-9_1_KQ089875\n",
      "blaSHV-12_1_KF976405\n",
      "blaSHV-48_1_AY263404\n",
      "blaTEM-1D_1_AF188200\n",
      "blaTEM-208_1_KC865667\n",
      "blaTEM-30_1_AJ437107\n",
      "blaTEM-33_1_GU371926\n",
      "blaTEM-35_1_KP860986\n",
      "blaTEM-40_1_FR717535\n",
      "blaTEM-84_1_AF427130\n",
      "catA1_1_V00622\n",
      "catA2_1_X53796\n",
      "catB3_2_U13880\n",
      "catB8_1_AF227506\n",
      "cmlA1_1_M64556\n",
      "cml_1_M22614\n",
      "dfrA12_8_AM040708\n",
      "dfrA14_5_DQ388123\n",
      "dfrA15_2_AF221900\n",
      "dfrA17_6_AF180469\n",
      "dfrA19_1_EU855687\n",
      "dfrA1_1_FJ591049\n",
      "dfrA1_8_X00926\n",
      "dfrA21_1_AY552589\n",
      "dfrA25_1_DQ267940\n",
      "dfrA29_1_AM237806\n",
      "dfrA5_1_X12868\n",
      "dfrA7_1_AB161450\n",
      "dfrA7_5_AJ419170\n",
      "dfrA8_1_U10186\n",
      "dfrB1_1_U36276\n",
      "ere(A)_4_AF512546\n",
      "ere(A)_5_FN396877\n",
      "erm(B)_18_X66468\n",
      "floR_2_AF118107\n",
      "fosA7_1_LAPJ01000014\n",
      "lnu(F)_2_DQ836009\n",
      "lnu(G)_1_KX470419\n",
      "mcr-5.1_1_KY807921\n",
      "mcr-9_1_NZ_NAAN01000063.1\n",
      "mdf(A)_1_Y08743\n",
      "mef(B)_1_FJ196385\n",
      "mph(A)_1_D16251\n",
      "mph(A)_2_U36578\n",
      "mph(B)_1_D85892\n",
      "mph(E)_1_DQ839391\n",
      "msr(E)_1_FR751518\n",
      "oqxB_1_EU370913\n",
      "qepA4_1_KX580704\n",
      "qnrB19_1_EU432277\n",
      "qnrB1_1_DQ351241\n",
      "qnrB2_1_DQ351242\n",
      "qnrB4_1_DQ303921\n",
      "qnrB5_1_DQ303919\n",
      "qnrS1_1_AB187515\n",
      "rmtC_1_AB194779\n",
      "sul1_33_AJ564903\n",
      "sul1_5_EU780013\n",
      "sul2_13_AJ289135\n",
      "sul2_18_AJ830714\n",
      "sul2_1_AF542061\n",
      "sul2_21_AB366440\n",
      "sul3_2_AJ459418\n",
      "tet(34)_1_AB061440\n",
      "tet(A)_1_AJ313332\n",
      "tet(A)_3_AY196695\n",
      "tet(A)_4_AJ517790\n",
      "tet(A)_6_AF534183\n",
      "tet(B)_1_AP000342\n",
      "tet(B)_2_AF326777\n",
      "tet(C)_3_AF055345\n",
      "tet(D)_1_AF467077\n",
      "tet(M)_4_X75073\n",
      "tet(M)_6_M21136\n",
      "tet(M)_8_X04388\n"
     ]
    }
   ],
   "source": [
    "### So there is a major problem with comparing the two databases \n",
    "# Difference of scope (e.g. CARD only 1 variant per protein and include chromosomal mechanisms of resistance)\n",
    "# Variable inclusion of different genes/variants\n",
    "\n",
    "# This makes the two very difficult to compare, and conseqeuntly I'm planning on taking a more manual approach.\n",
    "# Essentially I will instead look at \"of the resfinder genes, which ones\" are also found using Resfinder\n",
    "# And matching by the NAMES alone!\n",
    "\n",
    "\n",
    "for k in x:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
